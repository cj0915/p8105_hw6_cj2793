---
title: "p8105_hw6_cj2793"
author: "Chenyu Jin"
date: "2024-11-20"
output: github_document
---

```{r message = FALSE}
library(tidyverse)
library(modelr)
library(mgcv)
set.seed(1)
```

## Problem 2

### 1. Import and clean data

```{r}
homicide_df = read_csv(file = "data/homicidedata.csv", na = c("Unknown", "NA", "")) |>
  mutate(reported_date = as.Date(as.character(reported_date), format = "%Y%m%d"))
```

```{r}
homicide_df <- homicide_df |>
  mutate(
    city_state = str_c(city, state, sep = ", "),
    solved = if_else(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)
  ) |>
  filter(
    !city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, AL"),
    victim_race %in% c("White", "Black")
  )

```

### 2. logistic regression for Baltimore, MD

```{r}
baltimore_df <- homicide_df |>
  filter(city_state == "Baltimore, MD")
```

```{r}
logistic_model <- glm(solved ~ victim_age + victim_sex + victim_race, 
                      data = baltimore_df, family = binomial())
```

```{r}
logistic_model |>
  broom::tidy(conf.int = TRUE) |>
  filter(term == "victim_sexMale") |> 
  mutate(
    OR = exp(estimate),
    CI_low = exp(conf.low),
    CI_high = exp(conf.high)
  ) |> 
  select(OR, CI_low, CI_high) |> 
  knitr::kable(digits = 3)
```

The adjusted odds ratio for solving homicides comparing male victims to female victims is 0.426 (CI: 0.324~0.558), keeping all other variables fixed.

### 3. logistic regression for each of the cities

```{r}
city_models <- homicide_df |>
  group_by(city_state) |>
  nest() |>
  mutate(
    model = map(data, ~ glm(solved ~ victim_age + victim_sex + victim_race, 
                            data = ., family = binomial())),
    results = map(model, ~ broom::tidy(.x, conf.int = TRUE) |>
                    filter(term == "victim_sexMale") |>
                    mutate(
                      OR = exp(estimate),
                      CI_low = exp(conf.low),
                      CI_high = exp(conf.high)
                    ) |>
                    select(OR, CI_low, CI_high))
  ) |>
  unnest(results) |>
  select(city_state, OR, CI_low, CI_high)
```

```{r}
city_models |>
  knitr::kable(digits = 3)
```

### 4. Create a plot to visualize the ORs and CIs

```{r plot for problem2}
city_models |>
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = CI_low, ymax = CI_high), width = 0.2) +
  labs(
    title = "Estimated Odds Ratios for Solving Homicides by City",
    x = "City, State",
    y = "Odds Ratio (Male vs Female Victims)"
  ) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The plot displays the estimated odds ratios (ORs) for solving homicides comparing male victims to female victims across different cities, with corresponding confidence intervals (CIs). Many cities have confidence intervals that cross 1, indicating no significant difference in solving rates between male and female victims. Wide confidence intervals suggest high variability in some cities such as Albuquerque, NM; Stockton, CA; and Fresno, CA.

## Problem 3

### 1. Import and clean data

```{r}
birthweight_df <- read_csv("data/birthweightdata.csv")
```

```{r}
birthweight_df <- birthweight_df  |> 
  janitor::clean_names() |>
  mutate(
    babysex = 
        case_match(babysex,
            1 ~ "male",
            2 ~ "female"
        ),
    babysex = fct_infreq(babysex),
    frace = 
        case_match(frace,
            1 ~ "white",
            2 ~ "black", 
            3 ~ "asian", 
            4 ~ "puerto rican", 
            8 ~ "other"),
    frace = fct_infreq(frace),
    mrace = 
        case_match(mrace,
            1 ~ "white",
            2 ~ "black", 
            3 ~ "asian", 
            4 ~ "puerto rican",
            8 ~ "other"),
    mrace = fct_infreq(mrace),
    malform = as.logical(malform)) |>
  drop_na()
```

### 2. Propose a regression model for birthweight

```{r plot1 for problem3}
birthweight_model <- lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, data = birthweight_df)

summary(birthweight_model)

birthweight_df_1 <- birthweight_df |>
  add_predictions(birthweight_model) |>
  add_residuals(birthweight_model)

# Plot residuals against fitted values
ggplot(birthweight_df_1, aes(x = pred, y = resid)) +
  geom_point(alpha = 0.5) +
  geom_smooth() +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values (Predicted Birthweight)",
    y = "Residuals"
  ) +
  theme_minimal()
```

The full model for predicting birthweight (bwt) includes a comprehensive set of variables that are believed to influence birthweight based on biological, maternal, and socioeconomic factors. Key predictors include baby characteristics such as sex, head circumference, and length at birth, which directly relate to physical growth. Maternal factors such as weight, height, age, and pre-pregnancy BMI are included because they influence maternal health and fetal growth. Socioeconomic factors like family income and parents' race are added as proxies for access to healthcare and resources, potentially impacting pregnancy outcomes. Pregnancy-specific variables, such as gestational age, parity, weight gain during pregnancy, and smoking behavior, are critical determinants of fetal growth and overall birthweight. Together, these predictors provide a broad and holistic view of factors affecting birthweight, aiming to capture both direct and indirect influences.

### 3. Cross Validation

```{r}
model_1 <- lm(bwt ~ blength + gaweeks, data = birthweight_df)

model_2 <- lm(bwt ~ bhead * blength * babysex, data = birthweight_df)

model_3 <- lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, data = birthweight_df)
```

```{r plot2 for problem3}
set.seed(1)
cv_df <- crossv_mc(birthweight_df, 100) |>
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
  )

cv_df <- cv_df |>
  mutate(
    model_1 = 
      map(train, \(df) lm(bwt ~ blength + gaweeks, data = df)),
    model_2 = 
      map(train, \(df) lm(bwt ~ bhead * blength * babysex, data = df)),
    model_3 = 
      map(train, \(df) lm(bwt ~ babysex + bhead + blength + delwt + fincome + frace + gaweeks + malform + menarche + mheight + momage + mrace + parity + pnumlbw + pnumsga + ppbmi + ppwt + smoken + wtgain, data = df)),
    rmse_model_1 = 
      map2_dbl(model_1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_2 = 
      map2_dbl(model_2, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_3 = 
      map2_dbl(model_3, test, \(mod, df) rmse(model = mod, data = df))
  )

cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
```

The violin plot shows the distribution of the RMSE (Root Mean Squared Error) for each of the three models based on 100 cross-validation iterations. Model 1, which only includes length at birth and gestational age as predictors, has the largest variability and highest RMSE values, indicating it performs the worst in predicting birthweight among the three models. Model 2, which includes head circumference, length, sex, and their interactions, shows an improvement in prediction accuracy, with lower RMSE values and narrower variability. Model 3, which is the full model incorporating a comprehensive set of predictors including maternal, socioeconomic, and baby characteristics, performs the best with the lowest RMSE and less variability, suggesting that including more relevant features leads to a more accurate prediction of birthweight.

Considering both model simplicity and predictive performance, Model 2 is the best choice. Model 1 has the worst predictive performance, as indicated by the highest RMSE, suggesting it lacks accuracy. While Model 3 offers the best predictive performance with the lowest RMSE, it is highly complex, incorporating many variables, making it difficult to interpret and potentially prone to overfitting. Model 2, on the other hand, strikes a good balance between simplicity and predictive performance. 